from __init__ import setup_project_paths
setup_project_paths()

import os
import streamlit as st
import tempfile
import numpy as np
import pandas as pd
from core.models.models_manager import ModelsManager

st.set_page_config(
        layout="wide",
        page_title="EEG Insights Agent",
        page_icon="üß¨"
    )

if 'page_initialized' not in st.session_state:
    st.session_state.page_initialized = True

st.title("üß† –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
manager = ModelsManager()

with st.sidebar:
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
    st.header("üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")
    try:
        import torch
        st.markdown("**PyTorch:** " + torch.__version__)

        if torch.cuda.is_available():
            st.success(f"‚úÖ CUDA: {torch.cuda.device_count()} —É—Å—Ç—Ä–æ–π—Å—Ç–≤")
            st.caption(f"GPU: {torch.cuda.get_device_name()}")
            st.caption(f"GPU RAM: {torch.cuda.get_device_properties(0).total_memory // 1024 // 1024} MB")
        else:
            st.warning("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            st.caption("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

    except ImportError:
        st.error("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    try:
        import tensorflow as tf
        st.markdown("**TensorFlow:** " + tf.__version__)
        gpu_devices = tf.config.list_physical_devices('GPU')
        if gpu_devices:
            st.success(f"‚úÖ TF GPU: {len(gpu_devices)} —É—Å—Ç—Ä–æ–π—Å—Ç–≤")
    except ImportError:
        pass
    try:
        import psutil
        st.markdown("**–°–∏—Å—Ç–µ–º–∞:**")
        st.caption(f"CPU: {psutil.cpu_count()} —è–¥–µ—Ä")
        st.caption(f"RAM: {psutil.virtual_memory().total // (1024**3)} GB")
    except ImportError:
        pass

st.subheader("üì• –î–æ–±–∞–≤–∏—Ç—å –º–æ–¥–µ–ª—å")

source_type = st.radio("–ò—Å—Ç–æ—á–Ω–∏–∫", ["–§–∞–π–ª", "HuggingFace Hub"], horizontal=True)

if source_type == "–§–∞–π–ª":
    model_type = st.selectbox(
        "–¢–∏–ø –º–æ–¥–µ–ª–∏",
        ["tensorflow", "pytorch", "lightgbm", "eegnet"]
    )
else:
    model_type = "transformers"

model_path = None

if source_type == "–§–∞–π–ª":
    uploaded = st.file_uploader("–§–∞–π–ª –º–æ–¥–µ–ª–∏", type=["h5", "pt", "bin", "pth", "ckpt", "pkl"])
    if uploaded:
        tmp_path = os.path.join(tempfile.gettempdir(), uploaded.name)
        with open(tmp_path, "wb") as f:
            f.write(uploaded.getvalue())
        model_path = tmp_path
        st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {uploaded.name}")
else:
    repo_id = st.text_input("HuggingFace repo_id", placeholder="org/model")
    if repo_id.strip():
        model_path = repo_id.strip()
        st.info(f"üì° –ë—É–¥–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {repo_id}")

if st.button("üöÄ –î–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É") and model_path:
    try:
        model_id = manager.add_model(
            name=None,
            model_type=model_type,
            file_path=model_path,
            metadata={"source": source_type}
        )
        st.success(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (ID={model_id})")
        st.rerun()
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

st.subheader("üìÇ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏")
models = manager.list_models()

if not models:
    st.info("üì• –ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
else:
    for m in models:
        with st.container(border=True):
            cols = st.columns([3, 2, 2, 1])

            with cols[0]:
                st.markdown(f"**{m['name']}**")
                st.caption(m["file_path"])

            with cols[1]:
                st.text(f"–¢–∏–ø: {m['model_type']}")
                st.text(f"–î–æ–±–∞–≤–ª–µ–Ω–∞: {m.get('created_at_formatted', '‚Äî')}")

            with cols[2]:
                is_active = st.session_state.get("current_model_id") == m['id']
                if is_active:
                    if st.button("‚è∏ –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å", key=f"deact_{m['id']}"):
                        st.session_state.pop("current_model", None)
                        st.session_state.pop("current_model_id", None)
                        st.rerun()
                else:
                    if st.button("‚ñ∂ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å", key=f"act_{m['id']}"):
                        try:
                            with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞..."):
                                model = manager.load_model(m['id'])
                            st.session_state["current_model"] = model
                            st.session_state["current_model_id"] = m['id']
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå {e}")

            with cols[3]:
                if st.button("üóë", key=f"del_{m['id']}"):
                    manager.delete_model(m['id'])
                    st.rerun()

st.subheader("üîÆ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å")

if "current_model" in st.session_state:
    model = st.session_state["current_model"]
    info = manager.get_model_info(st.session_state["current_model_id"])

    st.markdown(f"**–ê–∫—Ç–∏–≤–Ω–∞:** `{info['name']}`")
    try:
        st.json(model.get_info())
    except:
        pass

    model_type = info.get("model_type", "")

    # LightGBM –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
    if model_type == "lightgbm":
        if "loaded_features" not in st.session_state:
            st.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∏—á–∏")
        else:
            X, y = st.session_state["loaded_features"]
            if st.button("üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å (LightGBM)"):
                try:
                    preds = model.predict(X)
                    df = pd.DataFrame({"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ": preds})
                    if y is not None:
                        df["–ò—Å—Ç–∏–Ω–Ω–æ–µ"] = y
                    st.dataframe(df)
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ LightGBM: {e}")

    # EEGNet –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
    elif model_type == "eegnet":
        if "loaded_features" not in st.session_state:
            st.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ (—Å—ã—Ä—ã–µ –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)")
        else:
            X, y = st.session_state["loaded_features"]
            if st.button("üß† –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å (EEGNet)"):
                try:
                    preds = model.predict(X)
                    df = pd.DataFrame({"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ": preds})
                    if y is not None:
                        df["–ò—Å—Ç–∏–Ω–Ω–æ–µ"] = y
                    st.dataframe(df)
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ EEGNet: {e}")

    # Transformers
    elif model_type == "transformers":
        st.info("‚ö†Ô∏è –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è Transformers —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤—ã—à–µ (—Ç–µ–∫—Å—Ç/—Ç–∞–π–º-—Å–µ—Ä–∏–∏)")

    # PyTorch
    elif model_type == "pytorch":
        st.info("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–ª–æ–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ PyTorch –≤—ã—à–µ")

    # TensorFlow
    elif model_type == "tensorflow":
        st.info("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–ª–æ–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ TensorFlow –≤—ã—à–µ")

else:
    st.info("üì≠ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏")

import streamlit as st
import numpy as np
import pandas as pd
import tempfile
import os
from datetime import datetime

from __init__ import setup_project_paths
setup_project_paths()

from core.data.loader import load_edf, load_csv
from core.data.manager import DataManager
from core.data.sample import EEGSample
st.set_page_config(
    page_title="EEG Insights Agent",
    page_icon="üß¨",
    layout="wide")

st.title("üîó –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")

manager = DataManager()

st.subheader("üìÇ –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã")
uploaded_files = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ EEG —Ñ–∞–π–ª–æ–≤ (.edf –∏–ª–∏ .csv)", 
    type=["edf", "csv"], 
    accept_multiple_files=True
)

if not uploaded_files:
    st.info("üì• –í—ã–±–µ—Ä–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞")
else:
    file_types = [f.name.split('.')[-1].lower() for f in uploaded_files]
    if len(set(file_types)) > 1:
        st.error("‚ùå –í—Å–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ (.edf –∏–ª–∏ .csv)")
    else:
        file_type = file_types[0]
        st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ {len(uploaded_files)} —Ñ–∞–π–ª–æ–≤ —Ç–∏–ø–∞ .{file_type}")

        has_labels = False
        if file_type == "csv":
            st.subheader("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã CSV")
            col1, col2 = st.columns(2)
            with col1:
                sfreq = st.number_input("–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (Hz)", min_value=1.0, value=256.0)
            with col2:
                has_labels = st.checkbox("–§–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤")
        
        if st.button("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å", type="primary"):
            try:
                with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤..."):
                    samples = []
                    temp_files = []
                    
                    for uploaded_file in uploaded_files:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_type}') as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            tmp_file_path = tmp_file.name
                            temp_files.append(tmp_file_path)
                        
                        if file_type == "edf":
                            sample = load_edf(tmp_file_path)
                        else:
                            sample = load_csv(tmp_file_path, sfreq=sfreq, has_labels=has_labels)
                        
                        samples.append(sample)
                    
                    for tmp_file in temp_files:
                        try:
                            os.unlink(tmp_file)
                        except:
                            pass
                    
                    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏")
                    compatible = True
                    first_sample = samples[0]
                    report_data = []
                    
                    for i, sample in enumerate(samples):
                        file_name = uploaded_files[i].name
                        issues = []
                        
                        if sample.data.shape[0] != first_sample.data.shape[0]:
                            compatible = False
                            issues.append(f"–∫–∞–Ω–∞–ª—ã: {sample.data.shape[0]}‚â†{first_sample.data.shape[0]}")
                        
                        if set(sample.ch_names) != set(first_sample.ch_names):
                            compatible = False
                            issues.append("–Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤")
                        
                        if abs(sample.sfreq - first_sample.sfreq) > 0.1:
                            compatible = False
                            issues.append(f"—á–∞—Å—Ç–æ—Ç–∞: {sample.sfreq}‚â†{first_sample.sfreq}")
                        
                        status = "‚úÖ OK" if not issues else "‚ùå " + ", ".join(issues)
                        report_data.append({
                            '–§–∞–π–ª': file_name,
                            '–ö–∞–Ω–∞–ª–æ–≤': sample.data.shape[0],
                            '–û—Ç—Å—á—ë—Ç–æ–≤': f"{sample.data.shape[1]:,}",
                            '–°—Ç–∞—Ç—É—Å': status
                        })
                    
                    report_df = pd.DataFrame(report_data)
                    st.dataframe(report_df, use_container_width=True, hide_index=True)
                    
                    if compatible:
                        st.success("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ–≤–º–µ—Å—Ç–∏–º—ã!")
                        st.session_state.merge_samples = samples
                        st.session_state.merge_files = uploaded_files
                        st.session_state.merge_ready = True
                        st.session_state.merge_file_type = file_type
                    else:
                        st.error("‚ùå –ù–∞–π–¥–µ–Ω—ã –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ñ–∞–π–ª—ã")
                        if 'merge_ready' in st.session_state:
                            del st.session_state.merge_ready
                        
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

if st.session_state.get('merge_ready', False):
    
    merged_name = st.text_input("–ò–º—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:", value=f"merged_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    if st.button("üíæ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã", type="secondary", use_container_width=True):
        try:
            with st.spinner("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤..."):
                samples = st.session_state.merge_samples
                uploaded_files = st.session_state.merge_files
                file_type = st.session_state.merge_file_type
                
                file_names = [f.name for f in uploaded_files]
                sorted_indices = sorted(range(len(file_names)), key=lambda i: file_names[i])
                samples = [samples[i] for i in sorted_indices]
                uploaded_files = [uploaded_files[i] for i in sorted_indices]
                
                combined_data = np.concatenate([sample.data for sample in samples], axis=1)
                
                final_filename = f"{merged_name}.{file_type}"
                merged_sample = EEGSample(
                    data=combined_data,
                    sfreq=samples[0].sfreq,
                    ch_names=samples[0].ch_names,
                    raw_path=final_filename,
                    metadata={
                        "source_files": [f.name for f in uploaded_files],
                        "n_files": len(samples),
                        "total_samples": combined_data.shape[1],
                        "merged_at": datetime.now().isoformat()
                    }
                )
                
                merged_id = manager.add_sample(merged_sample, final_filename)
                
                for key in ['merge_samples', 'merge_files', 'merge_ready', 'merge_file_type']:
                    if key in st.session_state:
                        del st.session_state[key]
                
                st.success(f"‚úÖ –§–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã! ID: {merged_id}")
                
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏: {str(e)}")

from __init__ import setup_project_paths
setup_project_paths()
import streamlit as st
import os

if 'page_initialized' not in st.session_state:
    st.session_state.page_initialized = True
    st.set_page_config(
        layout="wide",
        initial_sidebar_state="expanded"
    )

st.title("üß† Models")

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model_cached(model_type: str, model_name: str, model_path: str):
    from core.models.registry import get_model
    # –ù–ï –ü–ï–†–ï–î–ê–Å–ú device - –ø—É—Å—Ç—å –º–æ–¥–µ–ª–∏ —Å–∞–º–∏ —Ä–µ—à–∞—é—Ç
    model = get_model(model_type, model_name)
    model.load(model_path)
    return model

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
st.sidebar.header("üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–∞")
try:
    import torch
    if torch.cuda.is_available():
        st.sidebar.success(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞ ({torch.cuda.device_count()} —É—Å—Ç—Ä–æ–π—Å—Ç–≤)")
        st.sidebar.info(f"–¢–µ–∫—É—â–µ–µ: {torch.cuda.get_device_name()}")
    else:
        st.sidebar.warning("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
except ImportError:
    st.sidebar.error("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π
st.subheader("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏")
uploaded_model = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ (.h5, .pt, .bin)", 
                                 type=["h5", "pt", "bin", "pth", "ckpt"])

model_path_to_use = None
if uploaded_model is not None:
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_model.name.split('.')[-1]}") as tmp_file:
        tmp_file.write(uploaded_model.getvalue())
        model_path_to_use = tmp_file.name
    st.success(f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_model.name}")

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
model_type = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –º–æ–¥–µ–ª–∏", ["transformers", "pytorch", "tensorflow"])
model_name = st.text_input("–ò–º—è –º–æ–¥–µ–ª–∏", "MyModel")

# –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
default_path = "cardiffnlp/twitter-roberta-base-sentiment-latest" if model_type == "transformers" else "models/tensorflow/eeg_v4.h5"
model_path = st.text_input("–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏", model_path_to_use or default_path)

if st.button("üöÄ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"):
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
        if model_type in ["pytorch", "tensorflow"] and not os.path.exists(model_path):
            st.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
            st.info("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–∞–≥—Ä—É–∑—á–∏–∫ —Ñ–∞–π–ª–æ–≤ –≤—ã—à–µ –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å.")
            st.stop()
        
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏..."):
            model = load_model_cached(model_type, model_name, model_path)
            st.session_state["current_model"] = model
            st.session_state["current_model_type"] = model_type
            st.success(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} ({model_type}) –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            info = model.get_info()
            st.json(info)
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")

if "current_model" in st.session_state:
    st.subheader("üîÆ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å")
    model = st.session_state["current_model"]
    model_type = st.session_state["current_model_type"]

    if model_type == "transformers":
        text_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç", "–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", height=100)
        if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç"):
            try:
                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑..."):
                    preds = model.predict([text_input])
                    st.write("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
                    st.write(preds)
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {e}")
    else:
        st.info("")